{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNtWgvwywe6/pqU66bxRU3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnudennis/applied-image-processing-with-deep-learning/blob/main/fine_tune_transformers_on_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSjlnWeKasZj"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IJFgkkmDbFhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "5VdIv1QmbXYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 200"
      ],
      "metadata": {
        "id": "mEwZvaBpUshw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## text classification\n",
        "\n",
        "- 也叫 sequence classification\n",
        "- sentiment analysis\n",
        "  - 情感分析，也是文本/序列分类\n",
        "    - 电商评价\n",
        "    - social web: weibo/tweet"
      ],
      "metadata": {
        "id": "T6AP2z6EVFJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### emotions数据集"
      ],
      "metadata": {
        "id": "kx8b1s0pbMG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "FrwXVDlvU7mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset('emotion')"
      ],
      "metadata": {
        "id": "ZyBfiOPSVCVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DatasetDict\n",
        "# 8:1:1\n",
        "emotions"
      ],
      "metadata": {
        "id": "Y331Z63uVCYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.keys()"
      ],
      "metadata": {
        "id": "UbK-tMO-VCav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions['train'], type(emotions['train']))\n",
        "print(emotions['train']['text'][:5])\n",
        "print(emotions['train']['label'][:5])\n",
        "print(emotions['train'][:5])"
      ],
      "metadata": {
        "id": "tSLUUs86VCdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions['train'].features, type(emotions['train'].features))\n",
        "print(emotions['train'].features['label'])\n",
        "print(emotions['train'].features['label'].int2str(0))\n",
        "print(emotions['train'].features['label'].names)"
      ],
      "metadata": {
        "id": "Wtmj4LvEVCfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int2str(idx):\n",
        "  labels = emotions['train'].features['label'].names\n",
        "  num_classes = len(labels)\n",
        "  if idx < 0 or idx >= num_classes:\n",
        "    raise ValueError(f'Invalid integer class label {idx}')\n",
        "  return labels[idx]\n",
        "  # return emotions['train'].features['label'].int2str(idx)"
      ],
      "metadata": {
        "id": "aU_fR7NEVCh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2str(2)"
      ],
      "metadata": {
        "id": "U5Q0CuXEVCkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data visualization analysis\n",
        "\n",
        "- dataset ==> dataFrame\n",
        "- label analysis: label freq\n",
        "- text length"
      ],
      "metadata": {
        "id": "8uw3gl0bYUF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### dataset to dataframe"
      ],
      "metadata": {
        "id": "DKLwZDM6YggV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_df = pd.DataFrame.from_dict(emotions['train'])\n",
        "print(emotions_df.shape, emotions_df.columns)\n",
        "emotions_df"
      ],
      "metadata": {
        "id": "HVD2DB4YYTjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_df['label_name'] = emotions_df['label'].apply(lambda x: int2str(x))\n",
        "emotions_df[:5]"
      ],
      "metadata": {
        "id": "H_bbuwUhYTmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### label analysis"
      ],
      "metadata": {
        "id": "x_G__Tb0Zjkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_df.label.value_counts()"
      ],
      "metadata": {
        "id": "7vKrI41hYToa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(emotions_df.label_name.value_counts()))\n",
        "emotions_df.label_name.value_counts()"
      ],
      "metadata": {
        "id": "qTx8-ttFYTq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "emotions_df['label_name'].value_counts(ascending=True).plot.barh()\n",
        "plt.title('freq of labels')"
      ],
      "metadata": {
        "id": "2LIPStQtYTtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### text length analysis"
      ],
      "metadata": {
        "id": "bFaOgEXAar8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "emotions_df['words per tweet'] = emotions_df['text'].str.split().apply(len)\n",
        "emotions_df.boxplot('words per tweet', by='label_name',\n",
        "                    # showfliers=False,\n",
        "                    grid=False,\n",
        "                    color='black')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('')"
      ],
      "metadata": {
        "id": "R92BmB79YTvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions_df['words per tweet'].max())\n",
        "print(emotions_df['words per tweet'].idxmax())"
      ],
      "metadata": {
        "id": "3JQbvXjsaqWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions_df.iloc[emotions_df['words per tweet'].idxmin()])\n",
        "print(emotions_df.iloc[emotions_df['words per tweet'].idxmin()].text)"
      ],
      "metadata": {
        "id": "KLsMKYGaaqYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MK8pqAioaqaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### text => tokens\n",
        "\n",
        "数据集转换为模型接受的输入类型\n",
        "\n",
        "- Subword Tokenization\n",
        "  - WordPiece\n",
        "    - BERT and DistilBERT\n",
        "- hugging face:\n",
        "  - ~/.cache/huggingface/\n",
        "- tokenizer\n",
        "  - tokenizer.vocab_size\n",
        "- model config\n",
        "  - tokenizer.model_max_length\n",
        "  - tokenizer.model_input_names"
      ],
      "metadata": {
        "id": "L0SEMsnNDjgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### tokenizer"
      ],
      "metadata": {
        "id": "JgdqNRZ2DxpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "9kOYNKZbYTxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt='distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "WbZ2KrQSDvBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncased\n",
        "print(tokenizer.encode('hello world'))\n",
        "print(tokenizer.encode('Hello world'))\n",
        "print(tokenizer.encode('HELLO WORLD'))"
      ],
      "metadata": {
        "id": "KZYCvHz0DvEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "id": "0OHGPwFuDvGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.model_max_length)\n",
        "print(tokenizer.model_input_names)"
      ],
      "metadata": {
        "id": "cOCrciCWDvJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for special_id in tokenizer.all_special_ids:\n",
        "    print(special_id, tokenizer.decode(special_id))"
      ],
      "metadata": {
        "id": "zWW6qi9hDvLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  tokenize the whole dataset"
      ],
      "metadata": {
        "id": "sLUmjYy_GT8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(lambda dataset: tokenizer(dataset['text'], padding=True, truncation=True))"
      ],
      "metadata": {
        "id": "o-_N-Nl0DvNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded"
      ],
      "metadata": {
        "id": "9Qq4PJHSDvPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(emotions_encoded['train']['input_ids']))\n",
        "emotions_encoded['train']['input_ids'][:3]"
      ],
      "metadata": {
        "id": "mf2SlUMGIOkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list to tensor\n",
        "emotions_encoded.set_format('torch', columns=['label', 'input_ids', 'attention_mask'])\n",
        "emotions_encoded"
      ],
      "metadata": {
        "id": "w6wcZv4VDvR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(emotions_encoded['train']['input_ids']))\n",
        "emotions_encoded['train']['attention_mask'][:3]"
      ],
      "metadata": {
        "id": "2zS4YTMhDvUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VicOP3NXb30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}